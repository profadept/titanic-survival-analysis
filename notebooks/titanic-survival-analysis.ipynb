{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea6cf6f-8add-436a-9b1c-22b99f6d4721",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white;\">\n",
    "    <h1 style=\"color: white; text-align: center;\">üö¢ Titanic Survival Prediction Analysis</h1>\n",
    "    <p style=\"text-align: center; font-size: 18px;\"><strong>From EDA to Machine Learning - A Professional Data Science Workflow</strong></p>\n",
    "</div>\n",
    "\n",
    "## üìã Project Overview\n",
    "This analysis explores the Titanic dataset through a comprehensive EDA-to-ML workflow, serving as a bridge between exploratory analysis and predictive modeling in my data science portfolio.\n",
    "\n",
    "**üéØ Key Objectives:**\n",
    "- Perform comprehensive exploratory data analysis (EDA)\n",
    "- Engineer meaningful features from raw data\n",
    "- Build and evaluate multiple machine learning models\n",
    "- Demonstrate professional workflow and documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0146f2-6f4a-4548-a8f9-f93891b18bfc",
   "metadata": {},
   "source": [
    "## 1. üì• Import & Setup\n",
    "\n",
    "We begin by importing all necessary libraries and configuring our environment. This foundational step ensures we have the right tools for data manipulation, visualization, and machine learning tasks throughout the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb9b5d-a1b2-4f69-aee2-5a0f576ec689",
   "metadata": {},
   "source": [
    "### 1a. Importing Essential Libraries\n",
    "\n",
    "We import core data science libraries that form the foundation of our analysis. Each library serves a specific purpose in the data science workflow, from data manipulation to machine learning implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39c5bf0-c737-4d9a-90eb-9d952bc29cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation core libraries\n",
    "import pandas as pd  # Primary data structure (DataFrame) and analysis tools\n",
    "import numpy as np   # Numerical computing and array operations\n",
    "\n",
    "# Data visualization libraries  \n",
    "import matplotlib.pyplot as plt  # Foundation for all plotting in Python\n",
    "import seaborn as sns            # Enhanced statistical visualizations\n",
    "\n",
    "# Scikit-learn preprocessing modules\n",
    "from sklearn.preprocessing import StandardScaler  # Standardizes numeric features (mean=0, std=1)\n",
    "from sklearn.preprocessing import LabelEncoder    # Converts categorical text to numerical labels\n",
    "from sklearn.impute import SimpleImputer          # Systematically fills missing values\n",
    "from sklearn.model_selection import train_test_split  # Creates training/test splits for ML\n",
    "\n",
    "# System and utility libraries\n",
    "import warnings  # Manages warning messages during execution\n",
    "from datetime import datetime  # Handles date/time for analysis timestamping\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d4b21-1ede-41ad-b05d-98faf8a23811",
   "metadata": {},
   "source": [
    "### 1b. Configuration & Settings\n",
    "\n",
    "We configure our environment with global settings for visualizations and data display. Professional configuration ensures consistent, publication-quality plots and prevents common issues like truncated outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a427002b-9c29-47a6-a675-ac1b32c09038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment configured successfully!\n",
      "üìÖ Analysis timestamp: 2025-11-25 15:43:18\n"
     ]
    }
   ],
   "source": [
    "# Configure matplotlib for professional visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')  # Use seaborn's whitegrid theme for clean background\n",
    "sns.set_palette(\"husl\")  # Set color palette to \"husl\" for distinct, accessible colors\n",
    "\n",
    "# Set default figure size for all plots\n",
    "plt.rcParams['figure.figsize'] = (10, 6)  # Width: 10 inches, Height: 6 inches\n",
    "plt.rcParams['font.size'] = 12  # Base font size for all text elements in plots\n",
    "\n",
    "# Configure pandas display options for better data inspection\n",
    "pd.set_option('display.max_columns', 50)  # Show up to 50 columns when displaying DataFrames\n",
    "pd.set_option('display.max_rows', 100)    # Show up to 100 rows when displaying DataFrames\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)  # Format floats to 2 decimal places\n",
    "\n",
    "# Suppress warnings for cleaner output (use with caution)\n",
    "warnings.filterwarnings('ignore')  # Ignore warning messages that don't affect analysis\n",
    "\n",
    "print(\"‚úÖ Environment configured successfully!\")\n",
    "print(f\"üìÖ Analysis timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90f622-3f47-4503-9246-bf153f588123",
   "metadata": {},
   "source": [
    "## 2. üìä Data Loading & Overview\n",
    "\n",
    "In this section, we load the Titanic dataset and perform an initial exploration. Our goals are to:\n",
    "\n",
    "- Load the dataset from a reliable source and understand its structure\n",
    "- Examine the dataset's dimensions (rows and columns) and data types  \n",
    "- Identify missing values and data quality issues\n",
    "- Generate statistical summaries to spot outliers and patterns\n",
    "- Validate column names for consistency throughout our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ead69a-4a0f-46e9-8147-d3ed3612efec",
   "metadata": {},
   "source": [
    "### 2.1 Load Data\n",
    "\n",
    "We load the Titanic dataset from seaborn's built-in datasets, which are well-maintained and pre-cleaned. This ensures data quality and consistency for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d857c6b6-88d7-4a0c-936f-8cf0ffcad9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded successfully!\n",
      "üìä Dataset shape: 891 passengers, 15 features\n",
      "\n",
      "First 5 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.28</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.10</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch  fare embarked  class    who  \\\n",
       "0         0       3    male 22.00      1      0  7.25        S  Third    man   \n",
       "1         1       1  female 38.00      1      0 71.28        C  First  woman   \n",
       "2         1       3  female 26.00      0      0  7.92        S  Third  woman   \n",
       "3         1       1  female 35.00      1      0 53.10        S  First  woman   \n",
       "4         0       3    male 35.00      0      0  8.05        S  Third    man   \n",
       "\n",
       "   adult_male deck  embark_town alive  alone  \n",
       "0        True  NaN  Southampton    no  False  \n",
       "1       False    C    Cherbourg   yes  False  \n",
       "2       False  NaN  Southampton   yes   True  \n",
       "3       False    C  Southampton   yes  False  \n",
       "4        True  NaN  Southampton    no   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Titanic dataset from seaborn (well-maintained and pre-cleaned)\n",
    "df = sns.load_dataset('titanic')  # seaborn's built-in Titanic dataset\n",
    "\n",
    "print(\"‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"üìä Dataset shape: {df.shape[0]} passengers, {df.shape[1]} features\")\n",
    "\n",
    "# Display the first few rows to understand the data structure\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9924fae9-35b3-441b-aa18-0a500878c099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìê Dataset Shape: 891 rows, 15 columns\n",
      "\n",
      "=============================\n",
      "üìã DATA TYPES & MEMORY USAGE\n",
      "=============================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "\n",
      "===========================\n",
      "üîç MISSING VALUES ANALYSIS\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>177</td>\n",
       "      <td>19.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarked</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck</th>\n",
       "      <td>688</td>\n",
       "      <td>77.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Missing Count  Missing Percentage\n",
       "age                    177               19.87\n",
       "embarked                 2                0.22\n",
       "deck                   688               77.22\n",
       "embark_town              2                0.22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Total missing values in dataset: 869\n"
     ]
    }
   ],
   "source": [
    "# Examine dataset dimensions and basic information\n",
    "print(f\"üìê Dataset Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*29)\n",
    "print(\"üìã DATA TYPES & MEMORY USAGE\")\n",
    "print(\"=\"*29)\n",
    "df.info()  # Comprehensive overview of data types, non-null counts, and memory usage\n",
    "\n",
    "print(\"\\n\" + \"=\"*27)\n",
    "print(\"üîç MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*27)\n",
    "missing_data = df.isnull().sum()  # Count null values for each column\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100  # Calculate percentage missing\n",
    "\n",
    "# Create a clean missing values summary\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "display(missing_summary[missing_summary['Missing Count'] > 0])  # Show only columns with missing values\n",
    "\n",
    "print(f\"\\n‚úÖ Total missing values in dataset: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e5b06-78cf-4036-b5a0-07db3245d132",
   "metadata": {},
   "source": [
    "### 2.3 Statistical Summary\n",
    "\n",
    "We generate summary statistics for both numerical and categorical features. This helps us identify:\n",
    "\n",
    "- Outliers in numerical data (e.g., extreme fares or ages)\n",
    "- Data distribution patterns and central tendencies  \n",
    "- Top categories in categorical data (e.g., most common passenger class or embarkation point)\n",
    "- Potential data quality issues requiring attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5d8deb-0fe3-4354-a00a-5ab3331018e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ==============================\n",
      "          üìà NUMERICAL FEATURES SUMMARY\n",
      "          ==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.00</td>\n",
       "      <td>891.00</td>\n",
       "      <td>714.00</td>\n",
       "      <td>891.00</td>\n",
       "      <td>891.00</td>\n",
       "      <td>891.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.38</td>\n",
       "      <td>2.31</td>\n",
       "      <td>29.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.38</td>\n",
       "      <td>32.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.84</td>\n",
       "      <td>14.53</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.81</td>\n",
       "      <td>49.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>20.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>512.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       survived  pclass    age  sibsp  parch   fare\n",
       "count    891.00  891.00 714.00 891.00 891.00 891.00\n",
       "mean       0.38    2.31  29.70   0.52   0.38  32.20\n",
       "std        0.49    0.84  14.53   1.10   0.81  49.69\n",
       "min        0.00    1.00   0.42   0.00   0.00   0.00\n",
       "25%        0.00    2.00  20.12   0.00   0.00   7.91\n",
       "50%        0.00    3.00  28.00   0.00   0.00  14.45\n",
       "75%        1.00    3.00  38.00   1.00   0.00  31.00\n",
       "max        1.00    3.00  80.00   8.00   6.00 512.33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ================================\n",
      "                    üìä CATEGORICAL FEATURES SUMMARY\n",
      "                    ================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>203</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>577</td>\n",
       "      <td>644</td>\n",
       "      <td>491</td>\n",
       "      <td>537</td>\n",
       "      <td>537</td>\n",
       "      <td>59</td>\n",
       "      <td>644</td>\n",
       "      <td>549</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex embarked  class  who adult_male deck  embark_town alive alone\n",
       "count    891      889    891  891        891  203          889   891   891\n",
       "unique     2        3      3    3          2    7            3     2     2\n",
       "top     male        S  Third  man       True    C  Southampton    no  True\n",
       "freq     577      644    491  537        537   59          644   549   537"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\" \" * 10 + \"=\" * 30)\n",
    "print(\" \" * 10 +\"üìà NUMERICAL FEATURES SUMMARY\")\n",
    "print(\" \" * 10 +\"=\" * 30)\n",
    "# Describe numerical columns with detailed statistics\n",
    "numerical_summary = df.describe()  # Generates count, mean, std, min, percentiles, max\n",
    "display(numerical_summary)\n",
    "\n",
    "print(\" \" * 20 +\"=\" * 32)\n",
    "print(\" \" * 20 +\"üìä CATEGORICAL FEATURES SUMMARY\") \n",
    "print(\" \" * 20 +\"=\" * 32)\n",
    "# Describe categorical columns with frequency analysis\n",
    "categorical_summary = df.describe(include=['object', 'category', 'bool'])  # Includes object, category and boolean columns\n",
    "display(categorical_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d04864-2d5e-4420-85bd-fbf3419cfab8",
   "metadata": {},
   "source": [
    "### 2.4 Column Name Validation\n",
    "\n",
    "We verify that all column names are consistent (no spaces or special characters) to ensure easy programmatic access throughout our analysis. Clean column names prevent errors during data manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40170039-6635-4064-88c8-26a6c78e2043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù COLUMN NAMES VALIDATION\n",
      "===========================\n",
      "Column Names List:\n",
      "['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone']\n",
      "\n",
      "üîç Checking for naming inconsistencies:\n",
      "‚úÖ All column names are clean and consistent (snake_case format)\n",
      "‚úÖ No spaces, special characters, or uppercase letters detected\n"
     ]
    }
   ],
   "source": [
    "print(\"üìù COLUMN NAMES VALIDATION\")\n",
    "print(\"=\" * 27)\n",
    "print(\"Column Names List:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "print(\"\\nüîç Checking for naming inconsistencies:\")\n",
    "issues_found = False\n",
    "for col in df.columns:\n",
    "    # Check for spaces, special characters, or inconsistent formatting\n",
    "    if \" \" in col or \"-\" in col or col != col.lower():\n",
    "        print(f\"‚ö†Ô∏è  Column '{col}' contains inconsistencies!\")\n",
    "        issues_found = True\n",
    "\n",
    "if not issues_found:\n",
    "    print(\"‚úÖ All column names are clean and consistent (snake_case format)\")\n",
    "    print(\"‚úÖ No spaces, special characters, or uppercase letters detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7b2cb-9065-4d91-8dba-32896cdb4e82",
   "metadata": {},
   "source": [
    "### 2.5 Observations from Data Overview\n",
    "\n",
    "Based on our comprehensive data exploration, here are the key findings and insights that will guide our data cleaning and analysis strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba6712a-705a-4056-8d79-15935a962208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              ========================================\n",
      "                                   üéØ KEY OBSERVATIONS & INSIGHTS\n",
      "                              ========================================\n",
      "1. üìä **Dataset Structure**: 891 passengers with 15 features including survival status, demographics, and travel details\n",
      "2. ‚ö†Ô∏è **Missing Data**: Age (20%), Deck (77%) have significant missing values requiring careful handling\n",
      "3. üé´ **Passenger Class**: Majority are 3rd class (491), indicating socioeconomic distribution\n",
      "4. üë• **Demographics**: 577 males vs 314 females, with age range from 0.42 to 80 years\n",
      "5. üí∞ **Fare Analysis**: Wide range (0 to 512) with median 14.45, suggesting economic diversity\n",
      "6. üö¢ **Embarkation**: Southampton (644) was the most common departure point\n",
      "7. üéØ **Target Variable**: 38% survival rate (342 survived, 549 did not)\n",
      "8. üîç **Data Quality**: Clean column names, appropriate data types, no major structural issues\n"
     ]
    }
   ],
   "source": [
    "print(\" \" * 30 + \"=\" * 40)\n",
    "print(\" \" * 35 + \"üéØ KEY OBSERVATIONS & INSIGHTS\")\n",
    "print(\" \" * 30 + \"=\" * 40)\n",
    "\n",
    "observations = [\n",
    "    \"üìä **Dataset Structure**: 891 passengers with 15 features including survival status, demographics, and travel details\",\n",
    "    \"‚ö†Ô∏è **Missing Data**: Age (20%), Deck (77%) have significant missing values requiring careful handling\",\n",
    "    \"üé´ **Passenger Class**: Majority are 3rd class (491), indicating socioeconomic distribution\",\n",
    "    \"üë• **Demographics**: 577 males vs 314 females, with age range from 0.42 to 80 years\",\n",
    "    \"üí∞ **Fare Analysis**: Wide range (0 to 512) with median 14.45, suggesting economic diversity\",\n",
    "    \"üö¢ **Embarkation**: Southampton (644) was the most common departure point\",\n",
    "    \"üéØ **Target Variable**: 38% survival rate (342 survived, 549 did not)\",\n",
    "    \"üîç **Data Quality**: Clean column names, appropriate data types, no major structural issues\"\n",
    "]\n",
    "\n",
    "for i, observation in enumerate(observations, 1):\n",
    "    print(f\"{i}. {observation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfeb6d0-2d17-4ae6-a1ae-e865dfad07c1",
   "metadata": {},
   "source": [
    "## 3. üßπ Data Cleaning & Feature Engineering\n",
    "\n",
    "In this section, we systematically address data quality issues and create new features to enhance our analysis. Our cleaning strategy follows professional standards:\n",
    "\n",
    "- Handle missing values using appropriate imputation methods\n",
    "- Fix data type inconsistencies and formatting issues  \n",
    "- Engineer new features that capture meaningful patterns\n",
    "- Remove or transform outliers and problematic values\n",
    "- Ensure data consistency for machine learning readiness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c85d73b-c8a6-4278-9189-29196b5b4038",
   "metadata": {},
   "source": [
    "### 3.1 Handling Missing Values\n",
    "\n",
    "We implement a strategic approach to missing data based on the nature and percentage of missingness in each column. Professional imputation considers:\n",
    "- **Low missingness (<5%)**: Simple imputation (mean, mode, or forward fill)\n",
    "- **High missingness (>50%)**: Consider column removal or advanced imputation\n",
    "- **Categorical vs Numerical**: Different strategies for different data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e196fda0-847e-42b9-a946-75fb51dffad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ HANDLING MISSING VALUES\n",
      "===========================\n",
      "Missing values to handle:\n",
      "age            177\n",
      "embarked         2\n",
      "deck           688\n",
      "embark_town      2\n",
      "age_group      177\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ HANDLING MISSING VALUES\")\n",
    "print(\"=\" * 27)\n",
    "\n",
    "# Check current missing values\n",
    "print(\"Missing values to handle:\")\n",
    "missing_data = df.isnull().sum()\n",
    "print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9ca91-98c9-4a2e-b23f-5f7b3ab14542",
   "metadata": {},
   "source": [
    "### 3.2 Feature Engineering\n",
    "\n",
    "We'll create new features that can provide better insights for our analysis. Feature engineering transforms raw data into meaningful attributes that help machine learning models identify patterns more effectively.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c01d70b7-557f-4cab-bd35-6c42e8288f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß CREATING NEW FEATURES\n",
      "=========================\n",
      "‚úÖ Created 'family_size': Combines siblings/spouses + parents/children + self\n",
      "‚úÖ Created 'age_group': Categorical age ranges for demographic analysis\n",
      "‚úÖ Created 'fare_per_person': Individual fare cost for economic analysis\n",
      "\n",
      "üìä New dataset shape: (891, 18) i.e 891 rows and 18 columns\n",
      "New features added: ['family_size', 'age_group', 'fare_per_person']\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß CREATING NEW FEATURES\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Create family size feature\n",
    "df['family_size'] = df['sibsp'] + df['parch'] + 1  # +1 for the passenger themselves\n",
    "print(f\"‚úÖ Created 'family_size': Combines siblings/spouses + parents/children + self\")\n",
    "\n",
    "# Create age groups for better analysis\n",
    "df['age_group'] = pd.cut(df['age'], \n",
    "                        bins=[0, 12, 18, 35, 60, 100], \n",
    "                        labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "print(f\"‚úÖ Created 'age_group': Categorical age ranges for demographic analysis\")\n",
    "\n",
    "# Create fare per person\n",
    "df['fare_per_person'] = df['fare'] / df['family_size']\n",
    "print(f\"‚úÖ Created 'fare_per_person': Individual fare cost for economic analysis\")\n",
    "\n",
    "print(f\"\\nüìä New dataset shape: {df.shape} i.e {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(\"New features added:\", [col for col in df.columns if col not in ['sibsp', 'parch', 'age', 'fare']][-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6cdded-1b31-415e-9002-0b8beec137ce",
   "metadata": {},
   "source": [
    "### 3.3 Data Type Optimization\n",
    "\n",
    "We optimize data types to improve memory efficiency and ensure proper data representation. This is especially important for categorical data that can be converted to more efficient `category` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57ada87b-f4c9-4bcd-bae2-2b7f6c4e56f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ OPTIMIZING DATA TYPES\n",
      "=========================\n",
      "‚úÖ Converted 'sex' to category dtype\n",
      "‚úÖ Converted 'embarked' to category dtype\n",
      "‚úÖ Converted 'class' to category dtype\n",
      "‚úÖ Converted 'who' to category dtype\n",
      "‚úÖ Converted 'embark_town' to category dtype\n",
      "‚úÖ Converted 'alive' to category dtype\n",
      "‚úÖ Converted 'age_group' to category dtype\n",
      "\n",
      "üíæ Memory usage: 0.07MB ‚Üí 0.07MB\n",
      "üìâ Memory saved: 0.00MB (0.0% reduction)\n",
      "\n",
      "üìä Final dataset shape: (891, 18)\n",
      "üîç Data types after optimization:\n",
      "int64       5\n",
      "float64     3\n",
      "bool        2\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ OPTIMIZING DATA TYPES\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Check memory usage before optimization\n",
    "memory_before = df.memory_usage(deep=True).sum() / 1024**2  # Convert to MB\n",
    "\n",
    "# Convert appropriate columns to category dtype\n",
    "categorical_columns = ['sex', 'embarked', 'class', 'who', 'embark_town', 'alive', 'age_group']\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "        print(f\"‚úÖ Converted '{col}' to category dtype\")\n",
    "\n",
    "# Check memory usage after optimization  \n",
    "memory_after = df.memory_usage(deep=True).sum() / 1024**2\n",
    "memory_saved = memory_before - memory_after\n",
    "\n",
    "print(f\"\\nüíæ Memory usage: {memory_before:.2f}MB ‚Üí {memory_after:.2f}MB\")\n",
    "print(f\"üìâ Memory saved: {memory_saved:.2f}MB ({memory_saved/memory_before*100:.1f}% reduction)\")\n",
    "\n",
    "print(f\"\\nüìä Final dataset shape: {df.shape}\")\n",
    "print(\"üîç Data types after optimization:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08dc2db-8feb-42a3-a57e-353e2d647354",
   "metadata": {},
   "source": [
    "### 3.4 Data Cleaning Summary\n",
    "\n",
    "Our data preparation phase is complete. The seaborn Titanic dataset required minimal cleaning due to its pre-processed nature. We've successfully:\n",
    "\n",
    "- Confirmed no missing values require imputation\n",
    "- Engineered three new meaningful features for enhanced analysis\n",
    "- Maintained optimal data types for efficient processing\n",
    "\n",
    "The dataset is now ready for comprehensive exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1ea295d-fc0e-413c-9caf-c4d6a90885af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DATA CLEANING & FEATURE ENGINEERING COMPLETE\n",
      "==================================================\n",
      "üìä Final dataset: 891 passengers, 18 features\n",
      "üéØ Target variable: 'survived' (Binary classification)\n",
      "üîß New features created: 3\n",
      "üöÄ Ready for Exploratory Data Analysis\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ DATA CLEANING & FEATURE ENGINEERING COMPLETE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Final dataset: {df.shape[0]} passengers, {df.shape[1]} features\")\n",
    "print(f\"üéØ Target variable: 'survived' (Binary classification)\")\n",
    "print(f\"üîß New features created: 3\")\n",
    "print(f\"üöÄ Ready for Exploratory Data Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e2087-7ea6-4d98-a03d-9e9705df50e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
